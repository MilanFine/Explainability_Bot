{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "aa79d828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.document_loaders import UnstructuredExcelLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph.message import MessagesState\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "import re\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "75f23a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global model used across both tools and RAG\n",
    "llm = ChatGroq(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    model_name=\"Qwen-Qwq-32b\",\n",
    "    temperature = 0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "58070ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File loader tool: Reads and preprocesses all 2 Excel files into structured DataFrames\n",
    "def load_excel_files():\n",
    "    file_paths = [\n",
    "        \"2025_06_20_D0_pre_opti_model.xlsx\",\n",
    "        \"2025_06_20_D0_load_cost_analysis_post_optimisation.xlsx\"\n",
    "    ]\n",
    "    dfs = {}\n",
    "    for path in file_paths:\n",
    "        if not path or not os.path.exists(path):\n",
    "            print(f\"Warning: File {path} not found\")\n",
    "            continue\n",
    "        try:\n",
    "            sheet_dfs = pd.read_excel(path, sheet_name=None)\n",
    "            for sheet_name, df in sheet_dfs.items():\n",
    "                key = f\"{os.path.basename(path).replace('.xlsx','')}__{sheet_name}\".lower()\n",
    "                dfs[key] = df\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {path}: {e}\")\n",
    "    return dfs\n",
    "\n",
    "# Load structured data\n",
    "structured_dfs = load_excel_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d030beff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File descriptions for context\n",
    "FILE_DESCRIPTIONS = {\n",
    "    \"pre_opti_model\": {\n",
    "        \"description\": \"Contains raw SKU data before optimization including alternate SKUs, demand forecasts, risk assessments, and original planning data\",\n",
    "        \"key_fields\": [\"material_sk\", \"alternate skus\", \"demand_at_dt\", \"%_At_Risk\", \"Action\", \"lcp_rank\", \"weights\", \"chosen\"],\n",
    "        \"use_cases\": [\n",
    "            \"alternate SKUs information\",\n",
    "            \"Reason for chosing particular SKU\",\n",
    "            \"original demand data\",\n",
    "            \"risk assessments\", \n",
    "            \"SKU characteristics\",\n",
    "            \"planning weights\",\n",
    "            \"unoptimized data\"\n",
    "        ]\n",
    "    },\n",
    "    \"post_optimisation\": {\n",
    "        \"description\": \"Contains optimized load assignments, cost analysis, and final allocation decisions after optimization\",\n",
    "        \"key_fields\": [\"load_id\", \"material_sk\", \"optimized_quantity\", \"cost_analysis\", \"final_allocation\"],\n",
    "        \"use_cases\": [\n",
    "            \"load assignments\",\n",
    "            \"optimized quantities\",\n",
    "            \"cost analysis\",\n",
    "            \"final allocations\",\n",
    "            \"post-optimization results\"\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a84a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def query_router(question: str) -> dict:\n",
    "    \"\"\"\n",
    "    Use LLM to intelligently route queries based on file descriptions and context.\n",
    "    Returns both the tool and the preferred data source.\n",
    "    \"\"\"\n",
    "    routing_prompt = f\"\"\"\n",
    "    You are a query routing assistant for a supply chain optimization system. \n",
    "    \n",
    "    Available data sources:\n",
    "    1. PRE_OPTI_MODEL: {FILE_DESCRIPTIONS['pre_opti_model']['description']}\n",
    "       - Key fields: {', '.join(FILE_DESCRIPTIONS['pre_opti_model']['key_fields'])}\n",
    "       - Best for: {', '.join(FILE_DESCRIPTIONS['pre_opti_model']['use_cases'])}\n",
    "    \n",
    "    2. POST_OPTIMISATION: {FILE_DESCRIPTIONS['post_optimisation']['description']}\n",
    "       - Key fields: {', '.join(FILE_DESCRIPTIONS['post_optimisation']['key_fields'])}\n",
    "       - Best for: {', '.join(FILE_DESCRIPTIONS['post_optimisation']['use_cases'])}\n",
    "    \n",
    "    Available tools:\n",
    "    - get_sku_info: Get detailed information about a specific SKU\n",
    "    - get_skus_in_load: Get all SKUs assigned to a specific load\n",
    "    - compare_skus: Compare multiple SKUs\n",
    "    - get_alternate_skus: Get all alternate SKUs that can be sent in a specific load_id\n",
    "    - structured_query_tool: For questions requiring numeric aggregation, counts, or filtering on tabular data (e.g., \"how many SKUs\", \"count of load_ids\", etc.)\n",
    "    - rag_chain_tool: General questions requiring document search\n",
    "    \n",
    "    User question: \"{question}\"\n",
    "    \n",
    "    Based on the question, determine:\n",
    "    1. Which tool is most appropriate\n",
    "    2. Which data source(s) would best answer the question\n",
    "    3. Brief reasoning for your choice\n",
    "    \n",
    "    Respond in this exact format:\n",
    "    TOOL: [tool_name]\n",
    "    DATA_SOURCE: [pre_opti_model|post_optimisation|both]\n",
    "    REASONING: [brief explanation]\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke(routing_prompt)\n",
    "        \n",
    "        # Parse the response\n",
    "        lines = response.content.strip().split('\\n')\n",
    "        result = {\"tool\": \"rag_chain_tool\", \"data_source\": \"both\", \"reasoning\": \"Default routing\"}\n",
    "        \n",
    "        for line in lines:\n",
    "            if line.startswith(\"TOOL:\"):\n",
    "                result[\"tool\"] = line.split(\":\", 1)[1].strip()\n",
    "            elif line.startswith(\"DATA_SOURCE:\"):\n",
    "                result[\"data_source\"] = line.split(\":\", 1)[1].strip()\n",
    "            elif line.startswith(\"REASONING:\"):\n",
    "                result[\"reasoning\"] = line.split(\":\", 1)[1].strip()\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in smart routing: {e}\")\n",
    "        # Fallback to rule-based routing\n",
    "        return fallback_query_router(question)\n",
    "    \n",
    "def fallback_query_router(question: str) -> dict:\n",
    "    \"\"\"Enhanced rule-based router as fallback.\"\"\"\n",
    "    q = question.lower()\n",
    "    \n",
    "    # Keywords that suggest pre-optimization data\n",
    "    pre_opti_keywords = [\n",
    "        \"alternate\", \"alternative\", \"original\", \"demand\", \"forecast\", \n",
    "        \"risk\", \"at_risk\", \"weight\", \"lcp_rank\", \"characteristics\",\n",
    "        \"planning\", \"unoptimized\", \"raw\"\n",
    "    ]\n",
    "    \n",
    "    # Keywords that suggest post-optimization data\n",
    "    post_opti_keywords = [\n",
    "        \"optimized\", \"allocated\", \"assigned\", \"cost\", \"final\", \n",
    "        \"result\", \"outcome\", \"solution\"\n",
    "    ]\n",
    "    \n",
    "    # Determine data source preference\n",
    "    pre_opti_score = sum(1 for keyword in pre_opti_keywords if keyword in q)\n",
    "    post_opti_score = sum(1 for keyword in post_opti_keywords if keyword in q)\n",
    "    \n",
    "    if pre_opti_score > post_opti_score:\n",
    "        data_source = \"pre_opti_model\"\n",
    "    elif post_opti_score > pre_opti_score:\n",
    "        data_source = \"post_optimisation\"\n",
    "    else:\n",
    "        data_source = \"both\"\n",
    "    \n",
    "    # Determine tool\n",
    "    if re.search(r\"(how many|number of)\\s+(skus|loads?|load_ids?).*action.*(?:as|=|with)?\\s*['\\\"]?(no change|swap-out \\(delete\\)|top-up \\(new\\)|top-up \\(update\\)|swap-in)['\\\"]?\", q):\n",
    "        tool = \"structured_query_tool\"\n",
    "    elif \"material_sk\" in q and \"compare\" in q:\n",
    "        tool = \"compare_skus\"\n",
    "    elif \"material_sk\" in q and (\"information\" in q or \"info\" in q or \"give\" in q):\n",
    "        tool = \"get_sku_info\"\n",
    "    elif \"load_id\" in q:\n",
    "        tool = \"get_skus_in_load\"\n",
    "    elif \"load_id\" in q and \"alternate\" in q:\n",
    "        tool = \"get_alternate_skus\"\n",
    "    else:\n",
    "        tool = \"rag_chain_tool\"\n",
    "    \n",
    "    return {\n",
    "        \"tool\": tool,\n",
    "        \"data_source\": data_source,\n",
    "        \"reasoning\": f\"Rule-based: Routed to {tool} due to structured keyword patterns or domain-specific fields.\"\n",
    "    }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6dbebb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool definitions using @tool decorator\n",
    "#tool to get information about specific SKUs by giving material_sk\n",
    "@tool\n",
    "def get_sku_info(question: str) -> str:\n",
    "    \"\"\"Get information for a specific SKU with smart data source selection.\"\"\"\n",
    "    routing_info = query_router(question)\n",
    "    \n",
    "    match = re.search(r\"\\bmaterial_sk\\s+(\\d+)\\b\", question)\n",
    "    if not match:\n",
    "        return \"Please provide a valid material_sk number.\"\n",
    "    \n",
    "    sku_id = int(match.group(1))\n",
    "    results = []\n",
    "    \n",
    "    # Search based on routing decision\n",
    "    if routing_info[\"data_source\"] in [\"pre_opti_model\", \"both\"]:\n",
    "        for key, df in structured_dfs.items():\n",
    "            if \"pre_opti_model\" in key and \"material_sk\" in df.columns:\n",
    "                result = df[df[\"material_sk\"] == sku_id]\n",
    "                if not result.empty:\n",
    "                    results.append(f\"PRE-OPTIMIZATION DATA:\\n{result.to_string(index=False)}\")\n",
    "    \n",
    "    if routing_info[\"data_source\"] in [\"post_optimisation\", \"both\"]:\n",
    "        for key, df in structured_dfs.items():\n",
    "            if \"post_optimisation\" in key and \"material_sk\" in df.columns:\n",
    "                result = df[df[\"material_sk\"] == sku_id]\n",
    "                if not result.empty:\n",
    "                    results.append(f\"POST-OPTIMIZATION DATA:\\n{result.to_string(index=False)}\")\n",
    "    \n",
    "    if results:\n",
    "        return f\"SKU Information for material_sk {sku_id}:\\n\" + \"\\n\\n\".join(results) + f\"\\n\\nRouting Decision: {routing_info['reasoning']}\"\n",
    "    else:\n",
    "        return f\"SKU with material_sk {sku_id} not found in the selected data sources.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0887896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tool to get information of all SKUs in a particular load_id\n",
    "@tool\n",
    "def get_skus_in_load(question: str) -> str:\n",
    "    \"\"\"Get all SKUs in a specific load with smart data source selection.\"\"\"\n",
    "    routing_info = query_router(question)\n",
    "    \n",
    "    match = re.search(r\"\\bload_id\\s+(\\d+)\", question)\n",
    "    if not match:\n",
    "        return \"Please provide a valid load_id number.\"\n",
    "    \n",
    "    load_id = int(match.group(1))\n",
    "    results = []\n",
    "    \n",
    "    # For load queries, we might need to check both sources\n",
    "    if routing_info[\"data_source\"] in [\"post_optimisation\", \"both\"]:\n",
    "        for key, df in structured_dfs.items():\n",
    "            if \"post_optimisation\" in key and \"load_id\" in df.columns:\n",
    "                skus = df[df[\"load_id\"] == load_id]\n",
    "                if not skus.empty:\n",
    "                    results.append(f\"POST-OPTIMIZATION LOAD DATA:\\n{skus.to_string(index=False)}\")\n",
    "    \n",
    "    # If question asks about alternates, also check pre-opti data\n",
    "    if \"alternate\" in question.lower() or routing_info[\"data_source\"] in [\"pre_opti_model\", \"both\"]:\n",
    "        # Get SKUs from load first, then find their alternates in pre-opti data\n",
    "        sku_ids = []\n",
    "        for key, df in structured_dfs.items():\n",
    "            if \"post_optimisation\" in key and \"load_id\" in df.columns:\n",
    "                load_skus = df[df[\"load_id\"] == load_id]\n",
    "                if not load_skus.empty and \"material_sk\" in df.columns:\n",
    "                    sku_ids.extend(load_skus[\"material_sk\"].tolist())\n",
    "        \n",
    "        if sku_ids:\n",
    "            for key, df in structured_dfs.items():\n",
    "                if \"pre_opti_model\" in key and \"material_sk\" in df.columns:\n",
    "                    alternate_info = df[df[\"material_sk\"].isin(sku_ids)]\n",
    "                    if not alternate_info.empty:\n",
    "                        results.append(f\"PRE-OPTIMIZATION DATA (for alternate analysis):\\n{alternate_info.to_string(index=False)}\")\n",
    "    \n",
    "    if results:\n",
    "        return f\"Information for load_id {load_id}:\\n\" + \"\\n\\n\".join(results) + f\"\\n\\nRouting Decision: {routing_info['reasoning']}\"\n",
    "    else:\n",
    "        return f\"No information found for load_id {load_id}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "48b61d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tool to compare two different SKUs given their material_sk\n",
    "@tool\n",
    "def compare_skus(question: str) -> str:\n",
    "    \"\"\"Compare two SKUs with smart data source selection.\"\"\"\n",
    "    routing_info = query_router(question)\n",
    "    \n",
    "    ids = re.findall(r\"\\bmaterial_sk\\s+(\\d+)\", question)\n",
    "    if len(ids) != 2:\n",
    "        return \"Please provide exactly two material_sk IDs for comparison.\"\n",
    "    \n",
    "    sku_ids = [int(id_str) for id_str in ids]\n",
    "    results = []\n",
    "    \n",
    "    # Search based on routing decision\n",
    "    if routing_info[\"data_source\"] in [\"pre_opti_model\", \"both\"]:\n",
    "        for key, df in structured_dfs.items():\n",
    "            if \"pre_opti_model\" in key and \"material_sk\" in df.columns:\n",
    "                rows = df[df[\"material_sk\"].isin(sku_ids)]\n",
    "                if not rows.empty:\n",
    "                    results.append(f\"PRE-OPTIMIZATION COMPARISON:\\n{rows.to_string(index=False)}\")\n",
    "    \n",
    "    if routing_info[\"data_source\"] in [\"post_optimisation\", \"both\"]:\n",
    "        for key, df in structured_dfs.items():\n",
    "            if \"post_optimisation\" in key and \"material_sk\" in df.columns:\n",
    "                rows = df[df[\"material_sk\"].isin(sku_ids)]\n",
    "                if not rows.empty:\n",
    "                    results.append(f\"POST-OPTIMIZATION COMPARISON:\\n{rows.to_string(index=False)}\")\n",
    "    \n",
    "    if results:\n",
    "        return f\"Comparison of material_sk {sku_ids[0]} and {sku_ids[1]}:\\n\" + \"\\n\\n\".join(results) + f\"\\n\\nRouting Decision: {routing_info['reasoning']}\"\n",
    "    else:\n",
    "        return f\"Could not find both SKUs {sku_ids[0]} and {sku_ids[1]} for comparison.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "86991f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_alternate_skus(question: str) -> str:\n",
    "    \"\"\"Suggest alternate SKUs for a given load_id using pre-opti data, excluding already selected SKUs.\"\"\"\n",
    "    import re\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Extract load_id - handle both string and numeric load_ids\n",
    "    match = re.search(r\"\\bload_id\\s+(\\w+)\", question, re.IGNORECASE)\n",
    "    if not match:\n",
    "        return \"Please provide a valid load_id in your question (e.g., 'load_id 12345').\"\n",
    "    \n",
    "    load_id_str = match.group(1)\n",
    "    \n",
    "    # Try to convert to int if it's numeric, otherwise keep as string\n",
    "    try:\n",
    "        load_id = int(load_id_str)\n",
    "    except ValueError:\n",
    "        load_id = load_id_str\n",
    "    \n",
    "    pre_df = None\n",
    "    post_df = None\n",
    "    pre_key = None\n",
    "    post_key = None\n",
    "    \n",
    "    # Identify the correct pre and post optimization files\n",
    "    for key, df in structured_dfs.items():\n",
    "        if \"pre_opti_model\" in key.lower() and \"load_id\" in df.columns:\n",
    "            # Check if this load_id exists in this dataframe\n",
    "            temp_df = df[df[\"load_id\"] == load_id]\n",
    "            if not temp_df.empty:\n",
    "                pre_df = temp_df.copy()\n",
    "                pre_key = key\n",
    "                break\n",
    "    \n",
    "    for key, df in structured_dfs.items():\n",
    "        if \"post_optimisation\" in key.lower() and \"load_id\" in df.columns:\n",
    "            # Check if this load_id exists in this dataframe\n",
    "            temp_df = df[df[\"load_id\"] == load_id]\n",
    "            if not temp_df.empty:\n",
    "                post_df = temp_df.copy()\n",
    "                post_key = key\n",
    "                break\n",
    "    \n",
    "    # Enhanced error handling\n",
    "    if pre_df is None or pre_df.empty:\n",
    "        available_pre_loads = []\n",
    "        for key, df in structured_dfs.items():\n",
    "            if \"pre_opti_model\" in key.lower() and \"load_id\" in df.columns:\n",
    "                available_pre_loads.extend(df[\"load_id\"].unique().tolist())\n",
    "        \n",
    "        if available_pre_loads:\n",
    "            sample_loads = available_pre_loads[:5]  # Show first 5 as examples\n",
    "            return f\"No pre-optimization data found for load_id {load_id}. Available load_ids include: {sample_loads}...\"\n",
    "        else:\n",
    "            return f\"No pre-optimization data found for load_id {load_id}. No pre-optimization files with load_id column found.\"\n",
    "    \n",
    "    if post_df is None or post_df.empty:\n",
    "        return f\"No post-optimization data found for load_id {load_id}. Cannot determine which SKUs are already selected.\"\n",
    "    \n",
    "    # Ensure material_sk column exists in both dataframes\n",
    "    if \"material_sk\" not in pre_df.columns:\n",
    "        return f\"material_sk column not found in pre-optimization data ({pre_key}).\"\n",
    "    \n",
    "    if \"material_sk\" not in post_df.columns:\n",
    "        return f\"material_sk column not found in post-optimization data ({post_key}).\"\n",
    "    \n",
    "    # Get SKUs used in post-optimization\n",
    "    used_skus = set(post_df[\"material_sk\"].unique())\n",
    "    \n",
    "    # Suggest alternate SKUs not used in post-optimization\n",
    "    alternate_df = pre_df[~pre_df[\"material_sk\"].isin(used_skus)].copy()\n",
    "    \n",
    "    if alternate_df.empty:\n",
    "        return f\"No alternate SKUs found for load_id {load_id}. All {len(used_skus)} SKUs from pre-optimization are already used in post-optimization.\"\n",
    "    \n",
    "    # Sort alternates by relevant criteria if columns exist\n",
    "    sort_columns = []\n",
    "    sort_ascending = []\n",
    "    \n",
    "    # Prioritize by demand (higher is better)\n",
    "    if 'demand_at_dt(HL)' in alternate_df.columns:\n",
    "        sort_columns.append('demand_at_dt(HL)')\n",
    "        sort_ascending.append(False)\n",
    "    elif 'demand' in alternate_df.columns:\n",
    "        sort_columns.append('demand')\n",
    "        sort_ascending.append(False)\n",
    "    \n",
    "    # Then by cost (lower is better)\n",
    "    if 'vilc_cost' in alternate_df.columns:\n",
    "        sort_columns.append('vilc_cost')\n",
    "        sort_ascending.append(True)\n",
    "    elif 'cost' in alternate_df.columns:\n",
    "        sort_columns.append('cost')\n",
    "        sort_ascending.append(True)\n",
    "    \n",
    "    # Then by LCP rank (lower is better)\n",
    "    if 'lcp_rank' in alternate_df.columns:\n",
    "        sort_columns.append('lcp_rank')\n",
    "        sort_ascending.append(True)\n",
    "    \n",
    "    # Apply sorting if any sort columns were found\n",
    "    if sort_columns:\n",
    "        alternate_df = alternate_df.sort_values(sort_columns, ascending=sort_ascending)\n",
    "    \n",
    "    # Prepare summary information\n",
    "    total_pre_skus = len(pre_df)\n",
    "    total_post_skus = len(used_skus)\n",
    "    total_alternates = len(alternate_df)\n",
    "    \n",
    "    # Get unique source-destination combinations\n",
    "    unique_routes = None\n",
    "    if 'source' in alternate_df.columns and 'destination' in alternate_df.columns:\n",
    "        unique_routes = len(alternate_df.groupby(['source', 'destination']))\n",
    "    \n",
    "    # Prepare the result\n",
    "    result_lines = []\n",
    "    result_lines.append(f\"ALTERNATE SKUs FOR LOAD_ID: {load_id}\")\n",
    "    result_lines.append(\"=\" * 50)\n",
    "    result_lines.append(f\"Pre-optimization SKUs available: {total_pre_skus}\")\n",
    "    result_lines.append(f\"Post-optimization SKUs selected: {total_post_skus}\")\n",
    "    result_lines.append(f\"Alternate SKUs found: {total_alternates}\")\n",
    "    \n",
    "    if unique_routes:\n",
    "        result_lines.append(f\"Unique source-destination routes: {unique_routes}\")\n",
    "    \n",
    "    result_lines.append(\"\")\n",
    "    result_lines.append(\"Data sources:\")\n",
    "    result_lines.append(f\"• Pre-optimization: {pre_key}\")\n",
    "    result_lines.append(f\"• Post-optimization: {post_key}\")\n",
    "    result_lines.append(\"\")\n",
    "    \n",
    "    # Show sorting criteria if applied\n",
    "    if sort_columns:\n",
    "        sort_desc = []\n",
    "        for i, col in enumerate(sort_columns):\n",
    "            direction = \"descending\" if not sort_ascending[i] else \"ascending\"\n",
    "            sort_desc.append(f\"{col} ({direction})\")\n",
    "        result_lines.append(f\"Sorted by: {', '.join(sort_desc)}\")\n",
    "        result_lines.append(\"\")\n",
    "    \n",
    "    result_lines.append(\"ALTERNATE SKUs DETAILS:\")\n",
    "    result_lines.append(\"-\" * 30)\n",
    "    \n",
    "    # Limit columns to display for readability\n",
    "    display_columns = ['material_sk', 'material_code'] if 'material_code' in alternate_df.columns else ['material_sk']\n",
    "    \n",
    "    # Add key columns if they exist\n",
    "    key_columns = ['source', 'destination', 'demand_at_dt(HL)', 'vilc_cost', 'lcp_rank', 'OOS%']\n",
    "    for col in key_columns:\n",
    "        if col in alternate_df.columns:\n",
    "            display_columns.append(col)\n",
    "    \n",
    "    # Ensure we don't exceed reasonable display width\n",
    "    if len(display_columns) > 8:\n",
    "        display_columns = display_columns[:8]\n",
    "    \n",
    "    # Display the results\n",
    "    try:\n",
    "        if len(alternate_df) > 20:\n",
    "            result_lines.append(\"TOP 20 ALTERNATE SKUs:\")\n",
    "            result_lines.append(alternate_df[display_columns].head(20).to_string(index=False))\n",
    "            result_lines.append(f\"\\n... and {len(alternate_df) - 20} more alternate SKUs available\")\n",
    "        else:\n",
    "            result_lines.append(alternate_df[display_columns].to_string(index=False))\n",
    "    except Exception as e:\n",
    "        # Fallback to basic display if formatting fails\n",
    "        result_lines.append(\"ALTERNATE SKUs (basic format):\")\n",
    "        result_lines.append(str(alternate_df.head(10)))\n",
    "        result_lines.append(f\"Error in detailed formatting: {str(e)}\")\n",
    "    \n",
    "    return \"\\n\".join(result_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "816618a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To create a memory instance\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    output_key=\"answer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9147fd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q4/hxp6nh153wn2bxw9mlgx74_00000gn/T/ipykernel_83987/2102473802.py:27: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embeddings = HuggingFaceEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "# Setup QA Chain for RAG\n",
    "chat_histories = {}\n",
    "def setup_qa_chain():\n",
    "    \"\"\"Set up the RAG chain for general questions.\"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    # Load Excel files as documents\n",
    "    file_paths = [\n",
    "        \"2025_06_20_D0_pre_opti_model.xlsx\",\n",
    "        \"2025_06_20_D0_load_cost_analysis_post_optimisation.xlsx\"\n",
    "    ]\n",
    "    \n",
    "    for path in file_paths:\n",
    "        if os.path.exists(path):\n",
    "            try:\n",
    "                loader = UnstructuredExcelLoader(path)\n",
    "                docs = loader.load()\n",
    "                documents.extend(docs)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {path} for RAG: {e}\")\n",
    "    \n",
    "    if not documents:\n",
    "        print(\"Warning: No documents loaded for RAG\")\n",
    "        return None\n",
    "    \n",
    "    # Create embeddings and vectorstore\n",
    "    embeddings = HuggingFaceEmbeddings()\n",
    "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "    \n",
    "    # Create prompt template\n",
    "    system_prompt = (\n",
    "        \"You are an assistant designed to provide clear and concise explanations for decision-making logic. \"\n",
    "        \"When the user asks a question, analyze the underlying data, constraints, and priorities that could have influenced the choice. \"\n",
    "        \"Always reason step-by-step using available context. Highlight key factors such as weights, %_At_Risk, Action, %_OOS, lcp_rank, or demand_at_dt(HL). \"\n",
    "        \"If you are uncertain due to missing context, clearly state that and suggest what additional data would help. \"\n",
    "        \"Keep explanations factual, structured, and under 4 sentences unless explicitly asked for a deeper dive.\"\n",
    "        \"\\n\\n{context}\"\n",
    "    )\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ])\n",
    "    \n",
    "    # Create RAG chain\n",
    "    qa_chain = create_retrieval_chain(\n",
    "        vectorstore.as_retriever(), \n",
    "        create_stuff_documents_chain(llm, prompt)\n",
    "    )\n",
    "\n",
    "    # add message history wrapper\n",
    "    qa_chain_with_memory = RunnableWithMessageHistory(\n",
    "        qa_chain,\n",
    "        lambda session_id: chat_histories.setdefault(session_id, ChatMessageHistory()),\n",
    "        input_messages_key=\"input\",\n",
    "        output_messages_key=\"answer\"\n",
    "    )\n",
    "    \n",
    "    return qa_chain_with_memory\n",
    "\n",
    "# Initialize QA chain\n",
    "qa_chain = setup_qa_chain()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8296578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To load data files as dataframes\n",
    "df_pre_opti = pd.read_excel(\"2025_06_20_D0_pre_opti_model.xlsx\")\n",
    "df_post_opti = pd.read_excel(\"2025_06_20_D0_load_cost_analysis_post_optimisation.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cb3d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tool to run pandas logic to answer questions\n",
    "@tool\n",
    "def structured_query_tool(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Use structured DataFrames to answer quantitative/dataframe-related queries directly.\n",
    "    Handles load counts, SKU action filtering, and other structured data lookups.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        q = question.lower().strip()\n",
    "\n",
    "        # Define canonical actions and their possible user variations\n",
    "        action_variants = {\n",
    "            \"no change\": [\"no change\", \"unchanged\"],\n",
    "            \"swap-out (delete)\": [\"swap-out\", \"swap out\", \"delete\", \"removed\", \"swap-out(delete)\"],\n",
    "            \"swap-out (update)\": [\"swap-out\", \"swap out\", \"update\", \"updated\", \"swap-out(update)\"],\n",
    "            \"swap-in\": [\"swap-in\", \"swap in\", \"added from swap\"],\n",
    "            \"top-up (new)\": [\"top-up new\", \"topup new\", \"top-up (new)\", \"topup (new)\", \"top-up(new)\"],\n",
    "            \"top-up (update)\": [\"top-up update\", \"topup update\", \"top-up (update)\", \"topup (update)\", \"top-up(update)\"]\n",
    "        }\n",
    "\n",
    "        # Try to extract the target (sku or load) and raw action from the question\n",
    "        target_match = re.search(r\"(how many|number of)\\s+(skus?|loads?|load_ids?)\", q)\n",
    "        target = target_match.group(2).lower().strip() if target_match else None\n",
    "\n",
    "        # Search for an action phrase in the question\n",
    "        matched_action = None\n",
    "        for canonical_action, variants in action_variants.items():\n",
    "            for variant in variants:\n",
    "                if variant in q:\n",
    "                    matched_action = canonical_action\n",
    "                    break\n",
    "            if matched_action:\n",
    "                break\n",
    "\n",
    "        if matched_action and target:\n",
    "            if 'Action' not in df_post_opti.columns:\n",
    "                return \"The column 'Action' was not found in the post-optimization data.\"\n",
    "\n",
    "            # Filter using canonical action\n",
    "            df_filtered = df_post_opti[df_post_opti['Action'].str.strip().str.lower() == matched_action.lower()]\n",
    "\n",
    "            if target in [\"skus\", \"sku\"]:\n",
    "                count = df_filtered.shape[0]\n",
    "                return f\"There are {count} SKUs with action '{matched_action}'.\"\n",
    "\n",
    "            elif target in [\"loads\", \"load\", \"load_ids\", \"load id\"]:\n",
    "                if 'load_id' not in df_post_opti.columns:\n",
    "                    return \"The column 'load_id' was not found in the post-optimization data.\"\n",
    "                count = df_filtered['load_id'].nunique()\n",
    "                return f\"There are {count} unique load_ids with at least one SKU having action '{matched_action}'.\"\n",
    "\n",
    "        # --- General: How many loads total ---\n",
    "        if re.match(r\"(how many|number of)\\s+loads?\\s*(are there|in the day)?\", q):\n",
    "            if 'load_id' in df_post_opti.columns:\n",
    "                unique_loads = df_post_opti['load_id'].nunique()\n",
    "                return f\"There are {unique_loads} unique loads in the day.\"\n",
    "            return \"The column 'load_id' was not found in the data.\"\n",
    "        \n",
    "        # --- Sum of PALs sent ---\n",
    "        if \"pal\" in q and (\"how many\" in q or \"number of\" in q):\n",
    "            if 'suggested_PAL' in df_post_opti.columns:\n",
    "                total_pal = df_post_opti['suggested_PAL'].sum()\n",
    "                return f\"A total of {total_pal} PALs were sent in the day.\"\n",
    "            return \"The column 'suggested_PAL' was not found in the post-optimization data.\"\n",
    "        \n",
    "        # --- Total cost of all loads ---\n",
    "        if \"total cost\" in q or (\"cost\" in q and \"all loads\" in q):\n",
    "            if 'total_cost_PAL' in df_post_opti.columns:\n",
    "                total_cost = df_post_opti['total_cost_PAL'].sum()\n",
    "                return f\"The total cost of all loads is {total_cost:,.2f}.\"\n",
    "            return \"The column 'total_cost_PAL' was not found in the post-optimization data.\"\n",
    "\n",
    "        return \"I'm not sure how to answer that using the structured data. Please check column names or rephrase your question.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error in structured query tool: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0247447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tool to answer general things about the data provided\n",
    "@tool\n",
    "def rag_chain_tool(question: str) -> str:\n",
    "    \"\"\"Use RAG with enhanced context about data sources.\"\"\"\n",
    "    routing_info = query_router(question)\n",
    "    \n",
    "    if qa_chain is None:\n",
    "        return \"RAG system is not available. Please check if the Excel files are loaded correctly.\"\n",
    "    \n",
    "    session_id = \"default\"\n",
    "    \n",
    "    # Add context about the routing decision to the question\n",
    "    enhanced_question = f\"\"\"\n",
    "    Question: {question}\n",
    "    \n",
    "    Context: Based on your question, the system identified that you likely need information from: {routing_info['data_source']}\n",
    "    Reasoning: {routing_info['reasoning']}\n",
    "    \n",
    "    Please provide a comprehensive answer using the available data, and mention which data source(s) you're referencing.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        result = qa_chain.invoke(\n",
    "            {\"input\": enhanced_question},\n",
    "            config={\"configurable\": {\"session_id\": session_id}} ) # Pass memory session ID)\n",
    "        return result[\"answer\"]\n",
    "    except Exception as e:\n",
    "        return f\"Error processing question with RAG: {str(e)}\"\n",
    "\n",
    "# Update the tools list\n",
    "enhanced_tools = [\n",
    "    get_sku_info, \n",
    "    get_skus_in_load, \n",
    "    compare_skus, \n",
    "    get_alternate_skus,\n",
    "    structured_query_tool,\n",
    "    rag_chain_tool\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "22458f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tool node\n",
    "tools = [get_sku_info, get_skus_in_load, get_alternate_skus, compare_skus, rag_chain_tool]\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8bea569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define graph nodes\n",
    "def call_model(state: MessagesState):\n",
    "    \"\"\"Call the LLM to determine if tools are needed.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Create a system message that helps the model decide on tool usage\n",
    "    system_message = AIMessage(content=(\n",
    "        \"You are an assistant designed to provide clear and concise explanations for decision-making logic and can answer questions about SKU data and load optimization. \"\n",
    "        \"When the user asks a question, analyze the underlying data, constraints, and priorities that could have influenced the choice. \"\n",
    "        \"Always reason step-by-step using available context. Highlight key factors such as weights, %_At_Risk, Action, %_OOS, lcp_rank, or demand_at_dt(HL). \"\n",
    "        \"You have access to tools to get specific information. \"\n",
    "        \"Analyze the user's question and use the appropriate tool if needed.\"\n",
    "    ))\n",
    "    \n",
    "    # Add tools to the LLM\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    response = llm_with_tools.invoke([system_message] + messages)\n",
    "    \n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: MessagesState):\n",
    "    \"\"\"Determine whether to continue with tools or end.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # If there are tool calls, continue to tools\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "# Build the graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Add edges\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        END: END,\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11073fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7cdf4342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with: Which SKUs are sent in load_id 34824676?\n",
      "Response: The SKUs included in load_id **34824676** are:\n",
      "\n",
      "- **material_sk 1895427** (material_code 104114)\n",
      "- **material_sk 1895547** (material_code 104116)\n",
      "\n",
      "These SKUs were assigned to this load after optimization, with no changes recommended to their planned PAL allocations. Let me know if you need additional details about either SKU!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Test with your original question\n",
    "    question = \"Which SKUs are sent in load_id 34824676?\"\n",
    "    #question = \"Explain why material_sk 56044 was chosen as a top-up or a swap-in SKU for load_id 34810301? \"\n",
    "    #question = \"How many loads have the Action as No Change?\"\n",
    "    #question = \"Give a list of alternate SKUs that can be used for the load_id 34779602.  \"\n",
    "\n",
    "    print(f\"Testing with: {question}\")\n",
    "    \n",
    "    try:\n",
    "        response = app.invoke({\n",
    "            \"messages\": [HumanMessage(content=question)]},\n",
    "            config={\"configurable\": {\"session_id\": \"streamlit_session\"}}\n",
    "        )\n",
    "        \n",
    "        final_message = response[\"messages\"][-1]\n",
    "        print(f\"Response: {final_message.content}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        \n",
    "    # Uncomment to run full test suite\n",
    "    # test_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d48e14f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing with: Explain why material_sk 56044 was chosen as a top-up or a swap-in SKU for load_id 34810301?\n",
    "# Response: Material_sk 56044 was chosen as a top-up or swap-in SKU for load_id 34810301 due to several key factors:\n",
    "\n",
    "# 1. **Available Capacity**: The load has an available_PAL of 3 and available_Weight of 1.191, indicating sufficient capacity to accommodate additional SKU.\n",
    "\n",
    "# 2. **Priority and Demand**: With an lcp_rank of 1, this SKU is prioritized for optimization. The demand_at_dt(HL) of 1097.712647 highlights a significant need for this SKU.\n",
    "\n",
    "# 3. **Stock Availability**: The Stock_on_hand_sr(HL) of 3322.0 ensures that there is adequate stock to meet the demand without risking stockouts.\n",
    "\n",
    "# 4. **Risk Management**: Despite a higher %_At_Risk of 0.925073, the \"Light load\" action and lower HL_weight of 0.203169 suggest manageable risk levels.\n",
    "\n",
    "# 5. **Operational Efficiency**: The absence of out-of-stock issues (%_OOS of 0.0) and the ability to handle higher weights (Weights of 18.0) make this SKU a balanced choice for maintaining operational efficiency.\n",
    "\n",
    "# Overall, material_sk 56044 offers a balance of availability, demand fulfillment, and manageable risk, making it an optimal choice for top-up or swap-in for load_id 34810301."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f4582679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dba5f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
